{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "\n",
    "from nipype import Node, Workflow\n",
    "from nipype.interfaces.fsl import SliceTimer, MCFLIRT, Smooth, ExtractROI\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def writer(MyList, tgtf):\n",
    "    MyFile=open(tgtf,'w')\n",
    "    MyList=map(lambda x:x+'\\n', MyList)\n",
    "    MyFile.writelines(MyList)\n",
    "    MyFile.close()\n",
    "\n",
    "def f_kendall(timeseries_matrix):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the Kendall's coefficient of concordance for a number of\n",
    "    time-series in the input matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries_matrix : ndarray\n",
    "        A matrix of ranks of a subset subject's brain voxels\n",
    "    Returns\n",
    "    -------\n",
    "    kcc : float\n",
    "        Kendall's coefficient of concordance on the given input matrix\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    nk = timeseries_matrix.shape\n",
    "\n",
    "    n = nk[0]\n",
    "    k = nk[1]\n",
    "\n",
    "    sr = np.sum(timeseries_matrix, 1)\n",
    "    sr_bar = np.mean(sr)\n",
    "    s = np.sum(np.power(sr, 2)) - n*np.power(sr_bar, 2)\n",
    "    kcc = 12 *s/np.power(k, 2)/(np.power(n, 3) - n)\n",
    "    return kcc\n",
    "\n",
    "def compute_reho(in_file, mask_file, cluster_size = 7, out_file = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the ReHo Map, by computing tied ranks of the timepoints,\n",
    "    followed by computing Kendall's coefficient concordance(KCC) of a\n",
    "    timeseries with its neighbours\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_file : nifti file\n",
    "        4D EPI File\n",
    "    mask_file : nifti file\n",
    "        Mask of the EPI File(Only Compute ReHo of voxels in the mask)\n",
    "    out_file : nifti file\n",
    "        Where to save result\n",
    "    cluster_size : integer\n",
    "        for a brain voxel the number of neighbouring brain voxels to use for\n",
    "        KCC.\n",
    "    Returns\n",
    "    -------\n",
    "    out_file : nifti file\n",
    "        ReHo map of the input EPI image\n",
    "    \"\"\"\n",
    "\n",
    "    res_fname = (in_file)\n",
    "    res_mask_fname = (mask_file)\n",
    "    CUTNUMBER = 10\n",
    "\n",
    "    if not (cluster_size == 27 or cluster_size == 19 or cluster_size == 7 or cluster_size == 18):\n",
    "        cluster_size = 27\n",
    "\n",
    "    nvoxel = cluster_size\n",
    "\n",
    "    res_img = nb.load(res_fname)\n",
    "    res_mask_img = nb.load(res_mask_fname)\n",
    "\n",
    "    res_data = res_img.get_data()\n",
    "    res_mask_data = res_mask_img.get_data()\n",
    "\n",
    "    print(res_data.shape)\n",
    "    (n_x, n_y, n_z, n_t) = res_data.shape\n",
    "\n",
    "    # \"flatten\" each volume of the timeseries into one big array instead of\n",
    "    # x,y,z - produces (timepoints, N voxels) shaped data array\n",
    "    res_data = np.reshape(res_data, (n_x*n_y*n_z, n_t), order='F').T\n",
    "\n",
    "    # create a blank array of zeroes of size n_voxels, one for each time point\n",
    "    Ranks_res_data = np.tile((np.zeros((1, (res_data.shape)[1]))),\n",
    "                             [(res_data.shape)[0], 1])\n",
    "\n",
    "    # divide the number of total voxels by the cutnumber (set to 10)\n",
    "    # ex. end up with a number in the thousands if there are tens of thousands\n",
    "    # of voxels\n",
    "    segment_length = np.ceil(float((res_data.shape)[1])/float(CUTNUMBER))\n",
    "\n",
    "    for icut in range(0, CUTNUMBER):\n",
    "\n",
    "        segment = None\n",
    "\n",
    "        # create a Numpy array of evenly spaced values from the segment\n",
    "        # starting point up until the segment_length integer\n",
    "        if not (icut == (CUTNUMBER - 1)):\n",
    "            segment = np.array(np.arange(icut * segment_length,\n",
    "                                         (icut+1) * segment_length))\n",
    "        else:\n",
    "            segment = np.array(np.arange(icut * segment_length,\n",
    "                                         (res_data.shape[1])))\n",
    "\n",
    "        segment = np.int64(segment[np.newaxis])\n",
    "\n",
    "        # res_data_piece is a chunk of the original timeseries in_file, but\n",
    "        # aligned with the current segment index spacing\n",
    "        res_data_piece = res_data[:, segment[0]]\n",
    "        nvoxels_piece = res_data_piece.shape[1]\n",
    "\n",
    "        # run a merge sort across the time axis, re-ordering the flattened\n",
    "        # volume voxel arrays\n",
    "        res_data_sorted = np.sort(res_data_piece, 0, kind='mergesort')\n",
    "        sort_index = np.argsort(res_data_piece, axis=0, kind='mergesort')\n",
    "\n",
    "        # subtract each volume from each other\n",
    "        db = np.diff(res_data_sorted, 1, 0)\n",
    "\n",
    "        # convert any zero voxels into \"True\" flag\n",
    "        db = db == 0\n",
    "\n",
    "        # return an n_voxel (n voxels within the current segment) sized array\n",
    "        # of values, each value being the sum total of TRUE values in \"db\"\n",
    "        sumdb = np.sum(db, 0)\n",
    "\n",
    "        temp_array = np.array(np.arange(0, n_t))\n",
    "        temp_array = temp_array[:, np.newaxis]\n",
    "\n",
    "        sorted_ranks = np.tile(temp_array, [1, nvoxels_piece])\n",
    "\n",
    "        if np.any(sumdb[:]):\n",
    "\n",
    "            tie_adjust_index = np.flatnonzero(sumdb)\n",
    "\n",
    "            for i in range(0, len(tie_adjust_index)):\n",
    "\n",
    "                ranks = sorted_ranks[:, tie_adjust_index[i]]\n",
    "\n",
    "                ties = db[:, tie_adjust_index[i]]\n",
    "\n",
    "                tieloc = np.append(np.flatnonzero(ties), n_t + 2)\n",
    "                maxties = len(tieloc)\n",
    "                tiecount = 0\n",
    "\n",
    "                while(tiecount < maxties -1):\n",
    "                    tiestart = tieloc[tiecount]\n",
    "                    ntied = 2\n",
    "                    while(tieloc[tiecount + 1] == (tieloc[tiecount] + 1)):\n",
    "                        tiecount += 1\n",
    "                        ntied += 1\n",
    "\n",
    "                    ranks[tiestart:tiestart + ntied] = np.ceil(np.float32(np.sum(ranks[tiestart:tiestart + ntied ]))/np.float32(ntied))\n",
    "                    tiecount += 1\n",
    "\n",
    "                sorted_ranks[:, tie_adjust_index[i]] = ranks\n",
    "\n",
    "        del db, sumdb\n",
    "        sort_index_base = np.tile(np.multiply(np.arange(0, nvoxels_piece), n_t), [n_t, 1])\n",
    "        sort_index += sort_index_base\n",
    "        del sort_index_base\n",
    "\n",
    "        ranks_piece = np.zeros((n_t, nvoxels_piece))\n",
    "\n",
    "        ranks_piece = ranks_piece.flatten(order='F')\n",
    "        sort_index = sort_index.flatten(order='F')\n",
    "        sorted_ranks = sorted_ranks.flatten(order='F')\n",
    "\n",
    "        ranks_piece[sort_index] = np.array(sorted_ranks)\n",
    "\n",
    "        ranks_piece = np.reshape(ranks_piece, (n_t, nvoxels_piece), order='F')\n",
    "\n",
    "        del sort_index, sorted_ranks\n",
    "\n",
    "        Ranks_res_data[:, segment[0]] = ranks_piece\n",
    "\n",
    "        sys.stdout.write('.')\n",
    "\n",
    "    Ranks_res_data = np.reshape(Ranks_res_data, (n_t, n_x, n_y, n_z), order='F')\n",
    "\n",
    "    K = np.zeros((n_x, n_y, n_z))\n",
    "\n",
    "    mask_cluster = np.ones((3, 3, 3))\n",
    "\n",
    "    if nvoxel == 19:\n",
    "        mask_cluster[0, 0, 0] = 0\n",
    "        mask_cluster[0, 2, 0] = 0\n",
    "        mask_cluster[2, 0, 0] = 0\n",
    "        mask_cluster[2, 2, 0] = 0\n",
    "        mask_cluster[0, 0, 2] = 0\n",
    "        mask_cluster[0, 2, 2] = 0\n",
    "        mask_cluster[2, 0, 2] = 0\n",
    "        mask_cluster[2, 2, 2] = 0\n",
    "        \n",
    "    elif nvoxel == 18:\n",
    "        # null mid disk and disky-shaped\n",
    "        mask_cluster[0, 0, 0] = 0\n",
    "        mask_cluster[0, 2, 0] = 0\n",
    "        mask_cluster[2, 0, 0] = 0\n",
    "        mask_cluster[2, 2, 0] = 0\n",
    "        mask_cluster[0, 0, 2] = 0\n",
    "        mask_cluster[0, 2, 2] = 0\n",
    "        mask_cluster[2, 0, 2] = 0\n",
    "        mask_cluster[2, 2, 2] = 0\n",
    "        mask_cluster[1, 0, 0] = 0\n",
    "        mask_cluster[1, 0, 1] = 0\n",
    "        mask_cluster[1, 0, 2] = 0\n",
    "        mask_cluster[1, 2, 0] = 0\n",
    "        mask_cluster[1, 2, 1] = 0\n",
    "        mask_cluster[1, 2, 2] = 0\n",
    "        mask_cluster[1, 1, 0] = 0\n",
    "        mask_cluster[1, 1, 2] = 0\n",
    "\n",
    "    elif nvoxel == 7:\n",
    "\n",
    "        mask_cluster[0, 0, 0] = 0\n",
    "        mask_cluster[0, 1, 0] = 0\n",
    "        mask_cluster[0, 2, 0] = 0\n",
    "        mask_cluster[0, 0, 1] = 0\n",
    "        mask_cluster[0, 2, 1] = 0\n",
    "        mask_cluster[0, 0, 2] = 0\n",
    "        mask_cluster[0, 1, 2] = 0\n",
    "        mask_cluster[0, 2, 2] = 0\n",
    "        mask_cluster[1, 0, 0] = 0\n",
    "        mask_cluster[1, 2, 0] = 0\n",
    "        mask_cluster[1, 0, 2] = 0\n",
    "        mask_cluster[1, 2, 2] = 0\n",
    "        mask_cluster[2, 0, 0] = 0\n",
    "        mask_cluster[2, 1, 0] = 0\n",
    "        mask_cluster[2, 2, 0] = 0\n",
    "        mask_cluster[2, 0, 1] = 0\n",
    "        mask_cluster[2, 2, 1] = 0\n",
    "        mask_cluster[2, 0, 2] = 0\n",
    "        mask_cluster[2, 1, 2] = 0\n",
    "        mask_cluster[2, 2, 2] = 0\n",
    "\n",
    "    for i in range(1, n_x - 1):\n",
    "        for j in range(1, n_y -1):\n",
    "            for k in range(1, n_z -1):\n",
    "\n",
    "                block = Ranks_res_data[:, i-1:i+2, j-1:j+2, k-1:k+2]\n",
    "                mask_block = res_mask_data[i-1:i+2, j-1:j+2, k-1:k+2]\n",
    "\n",
    "                if not(int(mask_block[1, 1, 1]) == 0):\n",
    "\n",
    "                    if nvoxel == 19 or nvoxel == 7 or nvoxel == 18:\n",
    "                        mask_block = np.multiply(mask_block, mask_cluster)\n",
    "\n",
    "                    R_block = np.reshape(block, (block.shape[0], 27),\n",
    "                                         order='F')\n",
    "                    mask_R_block = R_block[:, np.argwhere(np.reshape(mask_block, (1, 27), order='F') > 0)[:, 1]]\n",
    "\n",
    "                    K[i, j, k] = f_kendall(mask_R_block)\n",
    "\n",
    "    img = nb.Nifti1Image(K, header=res_img.get_header(),\n",
    "                         affine=res_img.get_affine())\n",
    "    \n",
    "    if out_file is not None:\n",
    "        reho_file = out_file\n",
    "    else:\n",
    "        reho_file = os.path.join(os.getcwd(), 'ReHo.nii.gz')\n",
    "    img.to_filename(reho_file)\n",
    "    \n",
    "    return reho_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Volumes/G_drive/Backup_06062020/ds000201/\"\n",
    "order_path = base + \"/SlTi/\"\n",
    "\n",
    "sbjpatt  = \"\"\n",
    "sess     = \"ses-1/func\"\n",
    "fmriname = \"_ses-1_task-rest_bold.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR    = 2.5\n",
    "fwhm  = 3\n",
    "dummy = 10\n",
    "n_sl  = 49\n",
    "rh    = 18 #27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikibooks.org/wiki/SPM/Slice_Timing\n",
    "\n",
    "os.makedirs(order_path, mode=777, exist_ok=True)\n",
    "\n",
    "# seq asc 1 2 3 4\n",
    "slice_order = list(np.arange(1, n_sl+1).astype(str))\n",
    "writer(slice_order, order_path + 'slti_1.txt') \n",
    "\n",
    "# seq desc 4 3 2 1\n",
    "slice_order = list(reversed(list(np.arange(1, n_sl+1).astype(str))))\n",
    "writer(slice_order, order_path + 'slti_2.txt') \n",
    "\n",
    "# int asc 1 3 2 4\n",
    "slice_order = list(np.arange(1, n_sl+1, 2).astype(str)) + list(np.arange(2, n_sl+1, 2).astype(str))\n",
    "writer(slice_order, order_path + 'slti_3.txt') \n",
    "\n",
    "# int desc 4 2 3 1\n",
    "slice_order = list(reversed(list(np.arange(1, n_sl+1, 2).astype(str)) + list(np.arange(2, n_sl+1, 2).astype(str))))\n",
    "writer(slice_order, order_path + 'slti_4.txt') \n",
    "\n",
    "# int2 asc 2 4 1 3\n",
    "slice_order = list(np.arange(2, n_sl+1, 2).astype(str)) + list(np.arange(1, n_sl+1, 2).astype(str))\n",
    "writer(slice_order, order_path + 'slti_5.txt') \n",
    "\n",
    "# int2 dsc 3 1 4 2\n",
    "slice_order = list(reversed(list(np.arange(2, n_sl+1, 2).astype(str)) + list(np.arange(1, n_sl+1, 2).astype(str))))\n",
    "writer(slice_order, order_path + 'slti_6.txt') \n",
    "\n",
    "n_last = 12 # how many \"noise\" permutation to use\n",
    "for rr in np.arange(7,n_last):\n",
    "    slice_order = list(shuffle(np.arange(1, n_sl+1).astype(str), random_state=rr))\n",
    "    writer(slice_order, order_path + 'slti_{}.txt'.format(rr)) # random permutation of slices   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rehos = []\n",
    "for sbj in sorted([sbj.split(\"/\")[-1].replace(\"sub-\",\"\") for sbj in glob.glob(base + \"sub-{}*\".format(sbjpatt))]):\n",
    "    fmri_nii = base + \"sub-{}/{}/\".format(sbj,sess) + \"sub-{}{}\".format(sbj,fmriname)\n",
    "    for opt in np.arange(1, n_last):\n",
    "        proc_ref   = '{}_preproc_{}'.format(sbj,opt)\n",
    "        extract    = Node(ExtractROI(t_min=dummy, t_size=-1, output_type='NIFTI_GZ'), name=\"extract\")\n",
    "        slicetimer = Node(SliceTimer(custom_order = order_path + \"slti_{}.txt\".format(opt), time_repetition=TR), name=\"slicetimer\")\n",
    "        mcflirt    = Node(MCFLIRT(mean_vol=True, save_plots=True), name=\"mcflirt\")\n",
    "        smooth     = Node(Smooth(fwhm=fwhm), name=\"smooth\")\n",
    "        preproc01  = Workflow(name=proc_ref, base_dir=base)\n",
    "        preproc01.connect([(extract,    slicetimer, [('roi_file', 'in_file')]),\n",
    "                           (slicetimer, mcflirt,    [('slice_time_corrected_file', 'in_file')]),\n",
    "                           (mcflirt,    smooth,     [('out_file', 'in_file')])])\n",
    "        extract.inputs.in_file = fmri_nii\n",
    "        preproc01.run('MultiProc', plugin_args={'n_procs': 1})\n",
    "        \n",
    "        basepath = base + \"/{}/smooth/\".format(proc_ref)\n",
    "        proc_f   = basepath + fmri_nii.split(\"/\")[-1].replace(\".nii.gz\",\"\") + \"_roi_st_mcf_smooth.nii.gz\"\n",
    "        in_f     = basepath + \"meanvol\"\n",
    "        out_f    = basepath + \"meanvol_bet\"\n",
    "        !fslmaths {proc_f} -Tmean {in_f}\n",
    "        !bet {in_f} {out_f} -m\n",
    "        \n",
    "        rehos.append([sbj, opt, compute_reho(proc_f, in_f + \"_bet\" + \"_mask.nii.gz\", rh, out_file = base + \"/\" + sbj + \"_\" + str(opt) + \"_ReHo.nii.gz\")])\n",
    "        shutil.rmtree(base + \"/{}/\".format(proc_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rehos = [[ff.split(\"/\")[-1].split(\"_\")[0], ff.split(\"/\")[-1].split(\"_\")[1], ff] for ff in glob.glob(base+\"*_ReHo.nii.gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.05\n",
    "res = pd.DataFrame(columns=['sbj', 'ord', 'rehoavg', 'rehopct'])\n",
    "for nii in rehos:\n",
    "    img = nb.load(nii[-1]).get_fdata()\n",
    "    img = img.ravel()\n",
    "    img = img[img>thr]    \n",
    "    if int(nii[1]) < 7:\n",
    "        res = res.append({\"sbj\":nii[0], \"ord\":nii[1], \"rehoavg\":np.nanmean(img), \"rehopct\":np.percentile(img,90)}, ignore_index = True)\n",
    "    else:\n",
    "        res = res.append({\"sbj\":nii[0], \"ord\":\"0\",    \"rehoavg\":np.nanmean(img), \"rehopct\":np.percentile(img,90)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"rehopct\"\n",
    "\n",
    "signif = pd.DataFrame(columns=['sbj', 'ord', 'reho', 'tt'])\n",
    "for sbj in np.unique(res.sbj.values):\n",
    "    rsel = res[res.sbj == sbj].sort_values([\"rehopct\",\"rehoavg\"])\n",
    "    \n",
    "    for oo in np.arange(0,7):\n",
    "        oo = str(oo)\n",
    "        t2 = (np.nanmean(rsel[rsel.ord == oo][metric].values - np.nanmean(rsel[rsel.ord == \"0\"][metric].values))) / \\\n",
    "            np.nanstd(rsel[rsel.ord == \"0\"][metric].values)\n",
    "        signif = signif.append({\"sbj\":sbj, \n",
    "                                \"ord\":oo, \n",
    "                                \"reho\":round(np.nanmean(rsel[rsel.ord == oo][metric].values),3), \n",
    "                                \"tt\": round(np.abs(t2), 3)}, ignore_index = True)\n",
    "\n",
    "signif = signif[(signif.ord != \"5\") & (signif.ord != \"6\")] # exclude impossible cases\n",
    "\n",
    "lls = []\n",
    "for sbj in np.unique(res.sbj.values):\n",
    "    rsel = signif[signif.sbj == sbj].sort_values([\"reho\",\"sbj\"])\n",
    "    lls.append(rsel[rsel.sbj==sbj].iloc[-1:].ord.values[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord_id, counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = np.array(lls).astype(int).ravel()\n",
    "y  = np.bincount(x)\n",
    "ii = np.nonzero(y)[0]\n",
    "print(\"ord_id, counts\")\n",
    "np.vstack((ii,y[ii])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbj</th>\n",
       "      <th>ord</th>\n",
       "      <th>reho</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.597</td>\n",
       "      <td>5.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.563</td>\n",
       "      <td>5.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sbj ord   reho     tt\n",
       "0  9001   0  0.580  0.000\n",
       "1  9001   1  0.582  0.790\n",
       "2  9001   2  0.584  1.257\n",
       "3  9001   3  0.597  5.903\n",
       "4  9001   4  0.563  5.937"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signif.sort_values([\"sbj\", \"tt\"]).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
