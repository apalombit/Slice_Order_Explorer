{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "\n",
    "from nipype import Node, Workflow\n",
    "from nipype.interfaces.fsl import SliceTimer, MCFLIRT, Smooth, ExtractROI\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def writer(MyList, tgtf):\n",
    "    MyFile=open(tgtf,'w')\n",
    "    MyList=map(lambda x:x+'\\n', MyList)\n",
    "    MyFile.writelines(MyList)\n",
    "    MyFile.close()\n",
    "\n",
    "def f_kendall(timeseries_matrix):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the Kendall's coefficient of concordance for a number of\n",
    "    time-series in the input matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries_matrix : ndarray\n",
    "        A matrix of ranks of a subset subject's brain voxels\n",
    "    Returns\n",
    "    -------\n",
    "    kcc : float\n",
    "        Kendall's coefficient of concordance on the given input matrix\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    nk = timeseries_matrix.shape\n",
    "\n",
    "    n = nk[0]\n",
    "    k = nk[1]\n",
    "\n",
    "    sr = np.sum(timeseries_matrix, 1)\n",
    "    sr_bar = np.mean(sr)\n",
    "    s = np.sum(np.power(sr, 2)) - n*np.power(sr_bar, 2)\n",
    "    kcc = 12 *s/np.power(k, 2)/(np.power(n, 3) - n)\n",
    "    return kcc\n",
    "\n",
    "def compute_reho(in_file, mask_file, cluster_size = 7, out_file = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the ReHo Map, by computing tied ranks of the timepoints,\n",
    "    followed by computing Kendall's coefficient concordance(KCC) of a\n",
    "    timeseries with its neighbours\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_file : nifti file\n",
    "        4D EPI File\n",
    "    mask_file : nifti file\n",
    "        Mask of the EPI File(Only Compute ReHo of voxels in the mask)\n",
    "    out_file : nifti file\n",
    "        Where to save result\n",
    "    cluster_size : integer\n",
    "        for a brain voxel the number of neighbouring brain voxels to use for\n",
    "        KCC.\n",
    "    Returns\n",
    "    -------\n",
    "    out_file : nifti file\n",
    "        ReHo map of the input EPI image\n",
    "    \"\"\"\n",
    "\n",
    "    res_fname = (in_file)\n",
    "    res_mask_fname = (mask_file)\n",
    "    CUTNUMBER = 10\n",
    "\n",
    "    if not (cluster_size == 27 or cluster_size == 19 or cluster_size == 7 or cluster_size == 18):\n",
    "        cluster_size = 27\n",
    "\n",
    "    nvoxel = cluster_size\n",
    "\n",
    "    res_img = nb.load(res_fname)\n",
    "    res_mask_img = nb.load(res_mask_fname)\n",
    "\n",
    "    res_data = res_img.get_data()\n",
    "    res_mask_data = res_mask_img.get_data()\n",
    "\n",
    "    print(res_data.shape)\n",
    "    (n_x, n_y, n_z, n_t) = res_data.shape\n",
    "\n",
    "    # \"flatten\" each volume of the timeseries into one big array instead of\n",
    "    # x,y,z - produces (timepoints, N voxels) shaped data array\n",
    "    res_data = np.reshape(res_data, (n_x*n_y*n_z, n_t), order='F').T\n",
    "\n",
    "    # create a blank array of zeroes of size n_voxels, one for each time point\n",
    "    Ranks_res_data = np.tile((np.zeros((1, (res_data.shape)[1]))),\n",
    "                             [(res_data.shape)[0], 1])\n",
    "\n",
    "    # divide the number of total voxels by the cutnumber (set to 10)\n",
    "    # ex. end up with a number in the thousands if there are tens of thousands\n",
    "    # of voxels\n",
    "    segment_length = np.ceil(float((res_data.shape)[1])/float(CUTNUMBER))\n",
    "\n",
    "    for icut in range(0, CUTNUMBER):\n",
    "\n",
    "        segment = None\n",
    "\n",
    "        # create a Numpy array of evenly spaced values from the segment\n",
    "        # starting point up until the segment_length integer\n",
    "        if not (icut == (CUTNUMBER - 1)):\n",
    "            segment = np.array(np.arange(icut * segment_length,\n",
    "                                         (icut+1) * segment_length))\n",
    "        else:\n",
    "            segment = np.array(np.arange(icut * segment_length,\n",
    "                                         (res_data.shape[1])))\n",
    "\n",
    "        segment = np.int64(segment[np.newaxis])\n",
    "\n",
    "        # res_data_piece is a chunk of the original timeseries in_file, but\n",
    "        # aligned with the current segment index spacing\n",
    "        res_data_piece = res_data[:, segment[0]]\n",
    "        nvoxels_piece = res_data_piece.shape[1]\n",
    "\n",
    "        # run a merge sort across the time axis, re-ordering the flattened\n",
    "        # volume voxel arrays\n",
    "        res_data_sorted = np.sort(res_data_piece, 0, kind='mergesort')\n",
    "        sort_index = np.argsort(res_data_piece, axis=0, kind='mergesort')\n",
    "\n",
    "        # subtract each volume from each other\n",
    "        db = np.diff(res_data_sorted, 1, 0)\n",
    "\n",
    "        # convert any zero voxels into \"True\" flag\n",
    "        db = db == 0\n",
    "\n",
    "        # return an n_voxel (n voxels within the current segment) sized array\n",
    "        # of values, each value being the sum total of TRUE values in \"db\"\n",
    "        sumdb = np.sum(db, 0)\n",
    "\n",
    "        temp_array = np.array(np.arange(0, n_t))\n",
    "        temp_array = temp_array[:, np.newaxis]\n",
    "\n",
    "        sorted_ranks = np.tile(temp_array, [1, nvoxels_piece])\n",
    "\n",
    "        if np.any(sumdb[:]):\n",
    "\n",
    "            tie_adjust_index = np.flatnonzero(sumdb)\n",
    "\n",
    "            for i in range(0, len(tie_adjust_index)):\n",
    "\n",
    "                ranks = sorted_ranks[:, tie_adjust_index[i]]\n",
    "\n",
    "                ties = db[:, tie_adjust_index[i]]\n",
    "\n",
    "                tieloc = np.append(np.flatnonzero(ties), n_t + 2)\n",
    "                maxties = len(tieloc)\n",
    "                tiecount = 0\n",
    "\n",
    "                while(tiecount < maxties -1):\n",
    "                    tiestart = tieloc[tiecount]\n",
    "                    ntied = 2\n",
    "                    while(tieloc[tiecount + 1] == (tieloc[tiecount] + 1)):\n",
    "                        tiecount += 1\n",
    "                        ntied += 1\n",
    "\n",
    "                    ranks[tiestart:tiestart + ntied] = np.ceil(np.float32(np.sum(ranks[tiestart:tiestart + ntied ]))/np.float32(ntied))\n",
    "                    tiecount += 1\n",
    "\n",
    "                sorted_ranks[:, tie_adjust_index[i]] = ranks\n",
    "\n",
    "        del db, sumdb\n",
    "        sort_index_base = np.tile(np.multiply(np.arange(0, nvoxels_piece), n_t), [n_t, 1])\n",
    "        sort_index += sort_index_base\n",
    "        del sort_index_base\n",
    "\n",
    "        ranks_piece = np.zeros((n_t, nvoxels_piece))\n",
    "\n",
    "        ranks_piece = ranks_piece.flatten(order='F')\n",
    "        sort_index = sort_index.flatten(order='F')\n",
    "        sorted_ranks = sorted_ranks.flatten(order='F')\n",
    "\n",
    "        ranks_piece[sort_index] = np.array(sorted_ranks)\n",
    "\n",
    "        ranks_piece = np.reshape(ranks_piece, (n_t, nvoxels_piece), order='F')\n",
    "\n",
    "        del sort_index, sorted_ranks\n",
    "\n",
    "        Ranks_res_data[:, segment[0]] = ranks_piece\n",
    "\n",
    "        sys.stdout.write('.')\n",
    "\n",
    "    Ranks_res_data = np.reshape(Ranks_res_data, (n_t, n_x, n_y, n_z), order='F')\n",
    "\n",
    "    K = np.zeros((n_x, n_y, n_z))\n",
    "\n",
    "    mask_cluster = np.ones((3, 3, 3))\n",
    "\n",
    "    if nvoxel == 19:\n",
    "        mask_cluster[0, 0, 0] = 0\n",
    "        mask_cluster[0, 2, 0] = 0\n",
    "        mask_cluster[2, 0, 0] = 0\n",
    "        mask_cluster[2, 2, 0] = 0\n",
    "        mask_cluster[0, 0, 2] = 0\n",
    "        mask_cluster[0, 2, 2] = 0\n",
    "        mask_cluster[2, 0, 2] = 0\n",
    "        mask_cluster[2, 2, 2] = 0\n",
    "        \n",
    "    elif nvoxel == 18:\n",
    "        # null mid disk and disky-shaped\n",
    "        mask_cluster[0, 0, 0] = 0\n",
    "        mask_cluster[0, 2, 0] = 0\n",
    "        mask_cluster[2, 0, 0] = 0\n",
    "        mask_cluster[2, 2, 0] = 0\n",
    "        mask_cluster[0, 0, 2] = 0\n",
    "        mask_cluster[0, 2, 2] = 0\n",
    "        mask_cluster[2, 0, 2] = 0\n",
    "        mask_cluster[2, 2, 2] = 0\n",
    "        mask_cluster[1, 0, 0] = 0\n",
    "        mask_cluster[1, 0, 1] = 0\n",
    "        mask_cluster[1, 0, 2] = 0\n",
    "        mask_cluster[1, 2, 0] = 0\n",
    "        mask_cluster[1, 2, 1] = 0\n",
    "        mask_cluster[1, 2, 2] = 0\n",
    "        mask_cluster[1, 1, 0] = 0\n",
    "        mask_cluster[1, 1, 2] = 0\n",
    "\n",
    "    elif nvoxel == 7:\n",
    "\n",
    "        mask_cluster[0, 0, 0] = 0\n",
    "        mask_cluster[0, 1, 0] = 0\n",
    "        mask_cluster[0, 2, 0] = 0\n",
    "        mask_cluster[0, 0, 1] = 0\n",
    "        mask_cluster[0, 2, 1] = 0\n",
    "        mask_cluster[0, 0, 2] = 0\n",
    "        mask_cluster[0, 1, 2] = 0\n",
    "        mask_cluster[0, 2, 2] = 0\n",
    "        mask_cluster[1, 0, 0] = 0\n",
    "        mask_cluster[1, 2, 0] = 0\n",
    "        mask_cluster[1, 0, 2] = 0\n",
    "        mask_cluster[1, 2, 2] = 0\n",
    "        mask_cluster[2, 0, 0] = 0\n",
    "        mask_cluster[2, 1, 0] = 0\n",
    "        mask_cluster[2, 2, 0] = 0\n",
    "        mask_cluster[2, 0, 1] = 0\n",
    "        mask_cluster[2, 2, 1] = 0\n",
    "        mask_cluster[2, 0, 2] = 0\n",
    "        mask_cluster[2, 1, 2] = 0\n",
    "        mask_cluster[2, 2, 2] = 0\n",
    "\n",
    "    for i in range(1, n_x - 1):\n",
    "        for j in range(1, n_y -1):\n",
    "            for k in range(1, n_z -1):\n",
    "\n",
    "                block = Ranks_res_data[:, i-1:i+2, j-1:j+2, k-1:k+2]\n",
    "                mask_block = res_mask_data[i-1:i+2, j-1:j+2, k-1:k+2]\n",
    "\n",
    "                if not(int(mask_block[1, 1, 1]) == 0):\n",
    "\n",
    "                    if nvoxel == 19 or nvoxel == 7 or nvoxel == 18:\n",
    "                        mask_block = np.multiply(mask_block, mask_cluster)\n",
    "\n",
    "                    R_block = np.reshape(block, (block.shape[0], 27),\n",
    "                                         order='F')\n",
    "                    mask_R_block = R_block[:, np.argwhere(np.reshape(mask_block, (1, 27), order='F') > 0)[:, 1]]\n",
    "\n",
    "                    K[i, j, k] = f_kendall(mask_R_block)\n",
    "\n",
    "    img = nb.Nifti1Image(K, header=res_img.get_header(),\n",
    "                         affine=res_img.get_affine())\n",
    "    \n",
    "    if out_file is not None:\n",
    "        reho_file = out_file\n",
    "    else:\n",
    "        reho_file = os.path.join(os.getcwd(), 'ReHo.nii.gz')\n",
    "    img.to_filename(reho_file)\n",
    "    \n",
    "    return reho_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Volumes/G_drive/Backup_06062020/ds000133/\"\n",
    "order_path = base + \"/SlTi/\"\n",
    "\n",
    "sbjpatt  = \"\"\n",
    "sess     = \"ses-pre/func\"\n",
    "fmriname = \"_ses-pre_task-rest_run-01_bold.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR    = 1.67136\n",
    "fwhm  = 3\n",
    "dummy = 10\n",
    "n_sl  = 30\n",
    "rh    = 18 #27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikibooks.org/wiki/SPM/Slice_Timing\n",
    "\n",
    "os.makedirs(order_path, mode=777, exist_ok=True)\n",
    "\n",
    "# seq asc 1 2 3 4\n",
    "slice_order = list(np.arange(1, n_sl+1).astype(str))\n",
    "writer(slice_order, order_path + 'slti_1.txt') \n",
    "\n",
    "# seq desc 4 3 2 1\n",
    "slice_order = list(reversed(list(np.arange(1, n_sl+1).astype(str))))\n",
    "writer(slice_order, order_path + 'slti_2.txt') \n",
    "\n",
    "# int asc 1 3 2 4\n",
    "slice_order = list(np.arange(1, n_sl+1, 2).astype(str)) + list(np.arange(2, n_sl+1, 2).astype(str))\n",
    "writer(slice_order, order_path + 'slti_3.txt') \n",
    "\n",
    "# int asc 4 2 3 1\n",
    "slice_order = list(reversed(list(np.arange(1, n_sl+1, 2).astype(str)) + list(np.arange(2, n_sl+1, 2).astype(str))))\n",
    "writer(slice_order, order_path + 'slti_4.txt') \n",
    "\n",
    "# int2 asc 2 4 1 3\n",
    "slice_order = list(np.arange(2, n_sl+1, 2).astype(str)) + list(np.arange(1, n_sl+1, 2).astype(str))\n",
    "writer(slice_order, order_path + 'slti_5.txt') \n",
    "\n",
    "# int2 dsc 3 1 4 2\n",
    "slice_order = list(reversed(list(np.arange(2, n_sl+1, 2).astype(str)) + list(np.arange(1, n_sl+1, 2).astype(str))))\n",
    "writer(slice_order, order_path + 'slti_6.txt') \n",
    "\n",
    "for rr in np.arange(7,27):\n",
    "    slice_order = list(shuffle(np.arange(1, n_sl+1).astype(str), random_state=rr))\n",
    "    writer(slice_order, order_path + 'slti_{}.txt'.format(rr)) # random permutation of slices   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rehos = []\n",
    "for sbj in sorted([sbj.split(\"/\")[-1].replace(\"sub-\",\"\") for sbj in glob.glob(base + \"sub-{}*\".format(sbjpatt))]):\n",
    "    fmri_nii = base + \"sub-{}/{}/\".format(sbj,sess) + \"sub-{}{}\".format(sbj,fmriname)\n",
    "    for opt in np.arange(1, 17):\n",
    "        #if (opt in [5,6] and n_sl%2==0): \n",
    "            # skip Siemens interleaved even cases unless n_sl is really even\n",
    "        \n",
    "        proc_ref   = '{}_preproc_{}'.format(sbj,opt)\n",
    "        extract    = Node(ExtractROI(t_min=dummy, t_size=-1, output_type='NIFTI_GZ'), name=\"extract\")\n",
    "        slicetimer = Node(SliceTimer(custom_order = order_path + \"slti_{}.txt\".format(opt), time_repetition=TR), name=\"slicetimer\")\n",
    "        mcflirt    = Node(MCFLIRT(mean_vol=True, save_plots=True), name=\"mcflirt\")\n",
    "        smooth     = Node(Smooth(fwhm=fwhm), name=\"smooth\")\n",
    "        preproc01  = Workflow(name=proc_ref, base_dir=base)\n",
    "        preproc01.connect([(extract,    slicetimer, [('roi_file', 'in_file')]),\n",
    "                           (slicetimer, mcflirt,    [('slice_time_corrected_file', 'in_file')]),\n",
    "                           (mcflirt,    smooth,     [('out_file', 'in_file')])])\n",
    "        extract.inputs.in_file = fmri_nii\n",
    "        preproc01.run('MultiProc', plugin_args={'n_procs': 1})\n",
    "        \n",
    "        basepath = base + \"/{}/smooth/\".format(proc_ref)\n",
    "        proc_f   = basepath + fmri_nii.split(\"/\")[-1].replace(\".nii.gz\",\"\") + \"_roi_st_mcf_smooth.nii.gz\"\n",
    "        in_f     = basepath + \"meanvol\"\n",
    "        out_f    = basepath + \"meanvol_bet\"\n",
    "        !fslmaths {proc_f} -Tmean {in_f}\n",
    "        !bet {in_f} {out_f} -m\n",
    "        \n",
    "        rehos.append([sbj, opt, compute_reho(proc_f, in_f + \"_bet\" + \"_mask.nii.gz\", rh, out_file = base + \"/\" + sbj + \"_\" + str(opt) + \"_ReHo.nii.gz\")])\n",
    "        shutil.rmtree(base + \"/{}/\".format(proc_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rehos = [[ff.split(\"/\")[-1].split(\"_\")[0], ff.split(\"/\")[-1].split(\"_\")[1], ff] for ff in glob.glob(base+\"*_ReHo.nii.gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.05\n",
    "res = pd.DataFrame(columns=['sbj', 'ord', 'rehoavg', 'rehopct'])\n",
    "for nii in rehos:\n",
    "    img = nb.load(nii[-1]).get_fdata()\n",
    "    img = img.ravel()\n",
    "    img = img[img>thr]    \n",
    "    if int(nii[1]) < 7:\n",
    "        res = res.append({\"sbj\":nii[0], \"ord\":nii[1], \"rehoavg\":np.nanmean(img), \"rehopct\":np.percentile(img,90)}, ignore_index = True)\n",
    "    else:\n",
    "        res = res.append({\"sbj\":nii[0], \"ord\":\"0\",      \"rehoavg\":np.nanmean(img), \"rehopct\":np.percentile(img,90)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"rehopct\"\n",
    "\n",
    "signif = pd.DataFrame(columns=['sbj', 'ord', 'reho', 'tt'])\n",
    "for sbj in np.unique(res.sbj.values):\n",
    "    rsel = res[res.sbj == sbj].sort_values([\"rehopct\",\"rehoavg\"])\n",
    "    \n",
    "    for oo in np.arange(0,7):\n",
    "        oo = str(oo)\n",
    "        t2 = (np.nanmean(rsel[rsel.ord == oo][metric].values - np.nanmean(rsel[rsel.ord == \"0\"][metric].values))) / \\\n",
    "            np.nanstd(rsel[rsel.ord == \"0\"][metric].values)\n",
    "        signif = signif.append({\"sbj\":sbj, \n",
    "                                \"ord\":oo, \n",
    "                                \"reho\":round(np.nanmean(rsel[rsel.ord == oo][metric].values),3), \n",
    "                                \"tt\": round(np.abs(t2), 3)}, ignore_index = True)\n",
    "\n",
    "signif = signif[(signif.ord != \"3\")] # exclude impossible cases\n",
    "\n",
    "lls = []\n",
    "for sbj in np.unique(res.sbj.values):\n",
    "    rsel = signif[signif.sbj == sbj].sort_values([\"reho\",\"sbj\"])\n",
    "    lls.append(rsel[rsel.sbj==sbj].iloc[-1:].ord.values[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord_id, counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 6],\n",
       "       [2, 9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = np.array(lls).astype(int).ravel()\n",
    "y  = np.bincount(x)\n",
    "ii = np.nonzero(y)[0]\n",
    "print(\"ord_id, counts\")\n",
    "np.vstack((ii,y[ii])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbj</th>\n",
       "      <th>ord</th>\n",
       "      <th>reho</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.434</td>\n",
       "      <td>1.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435</td>\n",
       "      <td>2.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.399</td>\n",
       "      <td>1.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.404</td>\n",
       "      <td>1.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.458</td>\n",
       "      <td>1.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03</td>\n",
       "      <td>6</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "      <td>2.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473</td>\n",
       "      <td>2.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbj ord   reho     tt\n",
       "0   01   0  0.429  0.000\n",
       "4   01   4  0.427  0.854\n",
       "5   01   5  0.426  1.440\n",
       "6   01   6  0.426  1.562\n",
       "2   01   2  0.434  1.953\n",
       "1   01   1  0.435  2.393\n",
       "7   02   0  0.402  0.000\n",
       "11  02   4  0.400  0.955\n",
       "12  02   5  0.400  1.041\n",
       "8   02   1  0.404  1.385\n",
       "13  02   6  0.399  1.478\n",
       "9   02   2  0.404  1.637\n",
       "14  03   0  0.463  0.000\n",
       "18  03   4  0.459  0.854\n",
       "19  03   5  0.458  1.381\n",
       "20  03   6  0.457  1.454\n",
       "16  03   2  0.471  2.466\n",
       "15  03   1  0.473  2.795\n",
       "21  04   0  0.470  0.000\n",
       "26  04   5  0.470  0.132"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signif.sort_values([\"sbj\", \"tt\"]).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
